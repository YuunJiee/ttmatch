{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388520a0",
   "metadata": {},
   "source": [
    "# ðŸ“ Table Tennis Match Prediction - Gold + EDA (Final Best)\n",
    "\n",
    "**Version**: Gold + EDA - Optimized with Exploratory Data Analysis\n",
    "\n",
    "**Performance**: \n",
    "- Private Score: 0.3596 âœ… **BEST**\n",
    "- Public Score: 0.3189\n",
    "- Delta: +0.0407 (excellent generalization)\n",
    "\n",
    "**Key Improvements over Gold Baseline**:\n",
    "1. âœ… Early rally features (first 3-4 strokes critical)\n",
    "2. âœ… Hand-spin combinations (tactical patterns)\n",
    "3. âœ… Improved lag features (previous 2 strokes)\n",
    "4. âœ… Score momentum features\n",
    "5. âœ… EDA-driven feature selection\n",
    "\n",
    "**Comparison**:\n",
    "- vs V6: +177 points (17.7% improvement)\n",
    "- vs Gold: +22 points (2.2% improvement)\n",
    "\n",
    "**Note**: This is the final competition version with the best private score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd17e2b",
   "metadata": {},
   "source": [
    "## 1. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# ðŸ”§ Configuration & Setup\n",
    "# =========================================================\n",
    "\n",
    "USE_GPU = True\n",
    "N_FOLDS = 5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Install packages\n",
    "print(\"Installing packages...\")\n",
    "# !pip -q install lightgbm catboost pandas numpy scikit-learn matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"âœ“ Setup complete\")\n",
    "print(f\"  Python: {sys.version.split(' ')[0]}\")\n",
    "print(f\"  Random Seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93865b",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[2/15] Loading data...\")\n",
    "\n",
    "try:\n",
    "    # Try loading from parent data/ directory (when running from notebooks/)\n",
    "    train_df = pd.read_csv(\"../data/train.csv\")\n",
    "    test_df = pd.read_csv(\"../data/test.csv\")\n",
    "    submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "    print(f\"âœ“ Data loaded from ../data/ directory\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        # Try loading from local data/ directory\n",
    "        train_df = pd.read_csv(\"data/train.csv\")\n",
    "        test_df = pd.read_csv(\"data/test.csv\")\n",
    "        submission_df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "        print(f\"âœ“ Data loaded from data/ directory\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Error: Data files not found\")\n",
    "        sys.exit(1)\n",
    "\n",
    "print(f\"\\n  Train: {train_df.shape}\")\n",
    "print(f\"  Test:  {test_df.shape}\")\n",
    "print(f\"  Submission: {submission_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a2ca5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“Š PART 1: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Run all cells in this section and review the outputs before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# EDA 1: Basic Statistics\n",
    "# =========================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EDA 1: BASIC STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Dataset Overview:\")\n",
    "print(f\"  Train rows: {len(train_df):,}\")\n",
    "print(f\"  Test rows:  {len(test_df):,}\")\n",
    "print(f\"  Train rallies: {train_df['rally_uid'].nunique():,}\")\n",
    "print(f\"  Test rallies:  {test_df['rally_uid'].nunique():,}\")\n",
    "\n",
    "print(\"\\n2. Rally Length Statistics:\")\n",
    "train_rally_len = train_df.groupby('rally_uid').size()\n",
    "test_rally_len = test_df.groupby('rally_uid').size()\n",
    "\n",
    "print(\"  Train Rally Length:\")\n",
    "print(f\"    Mean: {train_rally_len.mean():.2f}\")\n",
    "print(f\"    Median: {train_rally_len.median():.1f}\")\n",
    "print(f\"    Min: {train_rally_len.min()}\")\n",
    "print(f\"    Max: {train_rally_len.max()}\")\n",
    "\n",
    "print(\"\\n  Test Rally Length:\")\n",
    "print(f\"    Mean: {test_rally_len.mean():.2f}\")\n",
    "print(f\"    Median: {test_rally_len.median():.1f}\")\n",
    "print(f\"    Min: {test_rally_len.min()}\")\n",
    "print(f\"    Max: {test_rally_len.max()}\")\n",
    "\n",
    "print(\"\\n3. Missing Values:\")\n",
    "print(\"  Train:\")\n",
    "train_missing = train_df.isnull().sum()\n",
    "print(train_missing[train_missing > 0] if train_missing.sum() > 0 else \"    None\")\n",
    "\n",
    "print(\"\\n  Test:\")\n",
    "test_missing = test_df.isnull().sum()\n",
    "print(test_missing[test_missing > 0] if test_missing.sum() > 0 else \"    None\")\n",
    "\n",
    "print(\"\\n4. Target Variable (serverGetPoint) in Train:\")\n",
    "print(f\"  Server Win Rate: {train_df['serverGetPoint'].mean():.2%}\")\n",
    "print(f\"  Distribution:\")\n",
    "print(train_df['serverGetPoint'].value_counts(normalize=True).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246627cf",
   "metadata": {},
   "source": [
    "## 3. EDA - Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ed656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# EDA 2: Feature Distribution Comparison\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDA 2: FEATURE DISTRIBUTION (Train vs Test)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def compare_distributions(feature, train, test):\n",
    "    \"\"\"Compare distribution of a feature between train and test.\"\"\"\n",
    "    print(f\"\\n{feature}:\")\n",
    "    \n",
    "    # Value counts\n",
    "    train_dist = train[feature].value_counts(normalize=True).sort_index()\n",
    "    test_dist = test[feature].value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    # Common values\n",
    "    common_vals = set(train_dist.index) & set(test_dist.index)\n",
    "    if len(common_vals) > 0:\n",
    "        diff = []\n",
    "        for val in sorted(common_vals)[:10]:  # Show top 10\n",
    "            train_pct = train_dist.get(val, 0) * 100\n",
    "            test_pct = test_dist.get(val, 0) * 100\n",
    "            diff_pct = test_pct - train_pct\n",
    "            print(f\"  {val:>4}: Train={train_pct:5.2f}%, Test={test_pct:5.2f}%, Diff={diff_pct:+5.2f}%\")\n",
    "    \n",
    "    # Unique values\n",
    "    print(f\"  Unique in Train: {len(train_dist)}\")\n",
    "    print(f\"  Unique in Test:  {len(test_dist)}\")\n",
    "    train_only = set(train_dist.index) - set(test_dist.index)\n",
    "    test_only = set(test_dist.index) - set(train_dist.index)\n",
    "    if train_only:\n",
    "        print(f\"  Only in Train: {len(train_only)} values\")\n",
    "    if test_only:\n",
    "        print(f\"  Only in Test: {len(test_only)} values\")\n",
    "\n",
    "# Compare key features\n",
    "features_to_compare = ['actionId', 'pointId', 'handId', 'spinId', 'strengthId', 'strickId']\n",
    "\n",
    "for feature in features_to_compare:\n",
    "    if feature in train_df.columns and feature in test_df.columns:\n",
    "        compare_distributions(feature, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e51110",
   "metadata": {},
   "source": [
    "## 4. EDA - Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829aec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# EDA 3: Score Distribution Analysis\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDA 3: SCORE DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'scoreSelf' in train_df.columns and 'scoreOther' in train_df.columns:\n",
    "    print(\"\\n1. Score Statistics:\")\n",
    "    print(\"  Train:\")\n",
    "    print(f\"    scoreSelf:  mean={train_df['scoreSelf'].mean():.2f}, max={train_df['scoreSelf'].max()}\")\n",
    "    print(f\"    scoreOther: mean={train_df['scoreOther'].mean():.2f}, max={train_df['scoreOther'].max()}\")\n",
    "    \n",
    "    if 'scoreSelf' in test_df.columns:\n",
    "        print(\"  Test:\")\n",
    "        print(f\"    scoreSelf:  mean={test_df['scoreSelf'].mean():.2f}, max={test_df['scoreSelf'].max()}\")\n",
    "        print(f\"    scoreOther: mean={test_df['scoreOther'].mean():.2f}, max={test_df['scoreOther'].max()}\")\n",
    "    \n",
    "    # Score difference\n",
    "    train_df['score_diff_temp'] = train_df['scoreSelf'] - train_df['scoreOther']\n",
    "    print(\"\\n2. Score Difference (scoreSelf - scoreOther):\")\n",
    "    print(f\"  Train: mean={train_df['score_diff_temp'].mean():.2f}, std={train_df['score_diff_temp'].std():.2f}\")\n",
    "    \n",
    "    # Critical points (score >= 9)\n",
    "    train_critical = ((train_df['scoreSelf'] >= 9) | (train_df['scoreOther'] >= 9)).sum()\n",
    "    print(f\"\\n3. Critical Points (either side >= 9):\")\n",
    "    print(f\"  Train: {train_critical:,} ({train_critical/len(train_df)*100:.2f}%)\")\n",
    "    \n",
    "    if 'scoreSelf' in test_df.columns:\n",
    "        test_df['score_diff_temp'] = test_df['scoreSelf'] - test_df['scoreOther']\n",
    "        print(f\"  Test: mean={test_df['score_diff_temp'].mean():.2f}, std={test_df['score_diff_temp'].std():.2f}\")\n",
    "        test_critical = ((test_df['scoreSelf'] >= 9) | (test_df['scoreOther'] >= 9)).sum()\n",
    "        print(f\"  Test: {test_critical:,} ({test_critical/len(test_df)*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"  Score columns not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865cac8",
   "metadata": {},
   "source": [
    "## 5. EDA - Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# EDA 4: Action Type Analysis\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDA 4: ACTION TYPE PATTERNS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create action type mapping\n",
    "action_map = {\n",
    "    1: 'Attack', 2: 'Attack', 3: 'Attack', 4: 'Attack', 5: 'Attack', 6: 'Attack', 7: 'Attack',\n",
    "    8: 'Control', 9: 'Control', 10: 'Control', 11: 'Control',\n",
    "    12: 'Defensive', 13: 'Defensive', 14: 'Defensive',\n",
    "    15: 'Serve', 16: 'Serve', 17: 'Serve', 18: 'Serve',\n",
    "    0: 'Zero', -1: 'End'\n",
    "}\n",
    "\n",
    "train_df['action_type_temp'] = train_df['actionId'].map(action_map).fillna('Unknown')\n",
    "test_df['action_type_temp'] = test_df['actionId'].map(action_map).fillna('Unknown')\n",
    "\n",
    "print(\"\\n1. Action Type Distribution:\")\n",
    "print(\"\\n  Train:\")\n",
    "train_action_dist = train_df['action_type_temp'].value_counts(normalize=True)\n",
    "for action, pct in train_action_dist.items():\n",
    "    print(f\"    {action:12s}: {pct*100:5.2f}%\")\n",
    "\n",
    "print(\"\\n  Test:\")\n",
    "test_action_dist = test_df['action_type_temp'].value_counts(normalize=True)\n",
    "for action, pct in test_action_dist.items():\n",
    "    print(f\"    {action:12s}: {pct*100:5.2f}%\")\n",
    "\n",
    "# Win rate by action type\n",
    "if 'serverGetPoint' in train_df.columns:\n",
    "    print(\"\\n2. Server Win Rate by Action Type:\")\n",
    "    win_by_action = train_df.groupby('action_type_temp')['serverGetPoint'].mean()\n",
    "    for action, rate in win_by_action.sort_values(ascending=False).items():\n",
    "        print(f\"    {action:12s}: {rate*100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fef478",
   "metadata": {},
   "source": [
    "## 6. EDA - Action Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac2e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# EDA 5: Rally Phase Analysis\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDA 5: RALLY PHASE PATTERNS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def get_rally_phase(n):\n",
    "    if n == 1: return 'Serve'\n",
    "    elif n == 2: return 'Return'\n",
    "    elif n <= 4: return 'Early'\n",
    "    else: return 'Extended'\n",
    "\n",
    "train_df['rally_phase_temp'] = train_df['strickNumber'].apply(get_rally_phase)\n",
    "test_df['rally_phase_temp'] = test_df['strickNumber'].apply(get_rally_phase)\n",
    "\n",
    "print(\"\\n1. Stroke Distribution by Rally Phase:\")\n",
    "print(\"\\n  Train:\")\n",
    "train_phase_dist = train_df['rally_phase_temp'].value_counts(normalize=True)\n",
    "for phase, pct in train_phase_dist.items():\n",
    "    print(f\"    {phase:12s}: {pct*100:5.2f}%\")\n",
    "\n",
    "print(\"\\n  Test:\")\n",
    "test_phase_dist = test_df['rally_phase_temp'].value_counts(normalize=True)\n",
    "for phase, pct in test_phase_dist.items():\n",
    "    print(f\"    {phase:12s}: {pct*100:5.2f}%\")\n",
    "\n",
    "# Win rate by rally phase\n",
    "if 'serverGetPoint' in train_df.columns:\n",
    "    print(\"\\n2. Server Win Rate by Rally Phase:\")\n",
    "    win_by_phase = train_df.groupby('rally_phase_temp')['serverGetPoint'].mean()\n",
    "    for phase, rate in win_by_phase.items():\n",
    "        print(f\"    {phase:12s}: {rate*100:5.2f}%\")\n",
    "\n",
    "# Action type by rally phase\n",
    "print(\"\\n3. Top Action Types by Rally Phase (Train):\")\n",
    "for phase in ['Serve', 'Return', 'Early', 'Extended']:\n",
    "    if phase in train_df['rally_phase_temp'].values:\n",
    "        print(f\"\\n  {phase}:\")\n",
    "        phase_actions = train_df[train_df['rally_phase_temp'] == phase]['action_type_temp'].value_counts(normalize=True).head(3)\n",
    "        for action, pct in phase_actions.items():\n",
    "            print(f\"    {action:12s}: {pct*100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51909408",
   "metadata": {},
   "source": [
    "## 7. EDA - Rally Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7994894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# EDA 6: Visualizations\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDA 6: VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "fig.suptitle('Train vs Test Distribution Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Rally Length Distribution\n",
    "ax = axes[0, 0]\n",
    "train_rally_len.value_counts().sort_index().head(20).plot(kind='bar', ax=ax, alpha=0.7, label='Train')\n",
    "test_rally_len.value_counts().sort_index().head(20).plot(kind='bar', ax=ax, alpha=0.7, label='Test')\n",
    "ax.set_title('Rally Length Distribution')\n",
    "ax.set_xlabel('Number of Strokes')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Action Type Distribution\n",
    "ax = axes[0, 1]\n",
    "# Get all unique action types from both train and test\n",
    "all_action_types = sorted(set(train_action_dist.index) | set(test_action_dist.index))\n",
    "x = np.arange(len(all_action_types))\n",
    "width = 0.35\n",
    "train_vals = [train_action_dist.get(action, 0) * 100 for action in all_action_types]\n",
    "test_vals = [test_action_dist.get(action, 0) * 100 for action in all_action_types]\n",
    "ax.bar(x - width/2, train_vals, width, label='Train', alpha=0.7)\n",
    "ax.bar(x + width/2, test_vals, width, label='Test', alpha=0.7)\n",
    "ax.set_title('Action Type Distribution')\n",
    "ax.set_ylabel('Percentage (%)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(all_action_types, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Rally Phase Distribution\n",
    "ax = axes[1, 0]\n",
    "phase_order = ['Serve', 'Return', 'Early', 'Extended']\n",
    "x = np.arange(len(phase_order))\n",
    "train_vals = [train_phase_dist.get(p, 0) * 100 for p in phase_order]\n",
    "test_vals = [test_phase_dist.get(p, 0) * 100 for p in phase_order]\n",
    "ax.bar(x - width/2, train_vals, width, label='Train', alpha=0.7)\n",
    "ax.bar(x + width/2, test_vals, width, label='Test', alpha=0.7)\n",
    "ax.set_title('Rally Phase Distribution')\n",
    "ax.set_ylabel('Percentage (%)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(phase_order)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Score Distribution (if available)\n",
    "ax = axes[1, 1]\n",
    "if 'scoreSelf' in train_df.columns and 'scoreSelf' in test_df.columns:\n",
    "    train_df['scoreSelf'].value_counts().sort_index().plot(kind='line', ax=ax, label='Train', marker='o')\n",
    "    test_df['scoreSelf'].value_counts().sort_index().plot(kind='line', ax=ax, label='Test', marker='s')\n",
    "    ax.set_title('Score Distribution (scoreSelf)')\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'Score data not available', ha='center', va='center', transform=ax.transAxes)\n",
    "    ax.set_title('Score Distribution')\n",
    "\n",
    "# 5. Server Win Rate by Action Type (Train only)\n",
    "ax = axes[2, 0]\n",
    "if 'serverGetPoint' in train_df.columns:\n",
    "    win_by_action.sort_values().plot(kind='barh', ax=ax, color='skyblue', alpha=0.7)\n",
    "    ax.set_title('Server Win Rate by Action Type (Train)')\n",
    "    ax.set_xlabel('Win Rate')\n",
    "    ax.axvline(0.5, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'Target variable not available', ha='center', va='center', transform=ax.transAxes)\n",
    "    ax.set_title('Server Win Rate by Action Type')\n",
    "\n",
    "# 6. actionId Distribution (Top 15)\n",
    "ax = axes[2, 1]\n",
    "train_action_id = train_df['actionId'].value_counts().head(15)\n",
    "test_action_id = test_df['actionId'].value_counts().head(15)\n",
    "all_actions = sorted(set(train_action_id.index) | set(test_action_id.index))\n",
    "x = np.arange(len(all_actions))\n",
    "train_vals = [train_action_id.get(a, 0) for a in all_actions]\n",
    "test_vals = [test_action_id.get(a, 0) for a in all_actions]\n",
    "ax.bar(x - width/2, train_vals, width, label='Train', alpha=0.7)\n",
    "ax.bar(x + width/2, test_vals, width, label='Test', alpha=0.7)\n",
    "ax.set_title('ActionId Distribution (Top 15)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(all_actions, rotation=45)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../analysis/eda_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nâœ“ Visualization saved to '../analysis/eda_analysis.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dfb981",
   "metadata": {},
   "source": [
    "## 8. EDA - Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075a6ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ”¨ PART 2: Feature Engineering (Based on EDA)\n",
    "\n",
    "**âš ï¸ DO NOT RUN YET - Wait for EDA-based adjustments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8caf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# ðŸ”¨ PART 2: Feature Engineering (EDA-Optimized)\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[3/8] Feature Engineering (EDA-Optimized)...\")\n",
    "\n",
    "def get_rally_phase(n):\n",
    "    \"\"\"Categorize rally by stroke number.\"\"\"\n",
    "    if n == 1: return 0      # Serve\n",
    "    elif n == 2: return 1    # Return\n",
    "    elif n <= 4: return 2    # Early\n",
    "    else: return 3           # Extended\n",
    "\n",
    "def create_features_eda(df):\n",
    "    \"\"\"\n",
    "    EDA-Optimized Feature Engineering\n",
    "    \n",
    "    Key insights from EDA:\n",
    "    1. Test has MUCH shorter rallies (median=2 vs train=5)\n",
    "    2. Test has MORE serves (32.7% vs 15.9%)\n",
    "    3. handId=1 is dominant in test (61% vs 45%)\n",
    "    4. spinId=2 and strengthId=2/3 more common in test\n",
    "    5. Early phases more important for test set\n",
    "    \"\"\"\n",
    "    df_feats = df.copy()\n",
    "    \n",
    "    # === 1. Basic Features ===\n",
    "    df_feats['rally_phase'] = df_feats['strickNumber'].apply(get_rally_phase)\n",
    "    \n",
    "    action_map = {\n",
    "        1: 'Attack', 2: 'Attack', 3: 'Attack', 4: 'Attack', 5: 'Attack', 6: 'Attack', 7: 'Attack',\n",
    "        8: 'Control', 9: 'Control', 10: 'Control', 11: 'Control',\n",
    "        12: 'Defensive', 13: 'Defensive', 14: 'Defensive',\n",
    "        15: 'Serve', 16: 'Serve', 17: 'Serve', 18: 'Serve',\n",
    "        0: 'Zero', -1: 'End'\n",
    "    }\n",
    "    df_feats['action_type'] = df_feats['actionId'].map(action_map).fillna('Zero')\n",
    "    \n",
    "    # Score features\n",
    "    if 'scoreSelf' in df_feats.columns and 'scoreOther' in df_feats.columns:\n",
    "        df_feats['score_diff'] = df_feats['scoreSelf'] - df_feats['scoreOther']\n",
    "        df_feats['score_sum'] = df_feats['scoreSelf'] + df_feats['scoreOther']\n",
    "        # Critical point indicator (21% of data)\n",
    "        df_feats['is_critical'] = ((df_feats['scoreSelf'] >= 9) | (df_feats['scoreOther'] >= 9)).astype(int)\n",
    "    \n",
    "    # === 2. EDA Insight: Early-phase specific features ===\n",
    "    # Since test has more early strokes, focus on serve/return characteristics\n",
    "    df_feats['is_serve_phase'] = (df_feats['strickNumber'] == 1).astype(int)\n",
    "    df_feats['is_return_phase'] = (df_feats['strickNumber'] == 2).astype(int)\n",
    "    df_feats['is_early'] = (df_feats['strickNumber'] <= 4).astype(int)\n",
    "    \n",
    "    # === 3. Lag-1 Features (most important for short rallies) ===\n",
    "    lag1_cols = ['strickId', 'handId', 'strengthId', 'spinId', 'pointId', \n",
    "                 'actionId', 'positionId', 'action_type']\n",
    "    for col in lag1_cols:\n",
    "        df_feats[f'prev_{col}'] = df_feats.groupby('rally_uid')[col].shift(1)\n",
    "    \n",
    "    # === 4. Conditional Lag-2 (only useful for longer rallies) ===\n",
    "    # Don't over-rely on Lag-2 since test rallies are shorter\n",
    "    lag2_cols = ['actionId', 'pointId']\n",
    "    for col in lag2_cols:\n",
    "        df_feats[f'prev2_{col}'] = df_feats.groupby('rally_uid')[col].shift(2)\n",
    "    \n",
    "    # === 5. Tactical Combinations ===\n",
    "    df_feats['prev_hand_spin'] = (\n",
    "        df_feats['prev_handId'].astype(str) + '_' + df_feats['prev_spinId'].astype(str)\n",
    "    )\n",
    "    df_feats['prev_action_point'] = (\n",
    "        df_feats['prev_actionId'].astype(str) + '_' + df_feats['prev_pointId'].astype(str)\n",
    "    )\n",
    "    df_feats['prev_action_phase'] = (\n",
    "        df_feats['prev_actionId'].astype(str) + '_ph' + df_feats['rally_phase'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # === 6. EDA-Driven: Hand-Spin-Strength combinations ===\n",
    "    # handId=1, spinId=2, strengthId=2/3 are more common in test\n",
    "    df_feats['hand_spin'] = (\n",
    "        df_feats['handId'].astype(str) + '_' + df_feats['spinId'].astype(str)\n",
    "    )\n",
    "    df_feats['hand_strength'] = (\n",
    "        df_feats['handId'].astype(str) + '_' + df_feats['strengthId'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # === 7. Action change indicator (rally dynamics) ===\n",
    "    df_feats['action_changed'] = (df_feats['actionId'] != df_feats['prev_actionId']).astype(int)\n",
    "    \n",
    "    # === 8. Fill Missing Values ===\n",
    "    for col in df_feats.columns:\n",
    "        if 'prev' in col:\n",
    "            df_feats[col] = df_feats[col].replace(\n",
    "                ['nan_nan', 'nan', '<NA>', '<NA>_<NA>'], np.nan\n",
    "            )\n",
    "        \n",
    "        if col.startswith('prev') or col in ['hand_spin', 'hand_strength']:\n",
    "            if df_feats[col].dtype == 'object':\n",
    "                df_feats[col] = df_feats[col].fillna('None')\n",
    "            else:\n",
    "                df_feats[col] = df_feats[col].fillna(-999)\n",
    "    \n",
    "    return df_feats\n",
    "\n",
    "# Create features\n",
    "print(\"  Creating EDA-optimized features...\")\n",
    "train_feats_df = create_features_eda(train_df)\n",
    "test_feats_df = create_features_eda(test_df)\n",
    "\n",
    "print(f\"âœ“ Feature engineering complete\")\n",
    "print(f\"  Train shape: {train_feats_df.shape}\")\n",
    "print(f\"  Test shape: {test_feats_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772fac7",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering (EDA-Optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707acd42",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ¤– PART 3: Model Training (Optimized)\n",
    "\n",
    "**âš ï¸ DO NOT RUN YET - Wait for EDA-based adjustments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d184983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# ðŸ¤– PART 3: Data Preparation & Model Training\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[4/8] Preparing Datasets...\")\n",
    "\n",
    "# Create target variables\n",
    "train_feats_df['next_actionId'] = train_feats_df.groupby('rally_uid')['actionId'].shift(-1)\n",
    "train_feats_df['next_pointId'] = train_feats_df.groupby('rally_uid')['pointId'].shift(-1)\n",
    "train_feats_df['rally_outcome'] = train_feats_df['serverGetPoint']\n",
    "\n",
    "# Filter rows with valid next actions\n",
    "train_next_df = train_feats_df.dropna(subset=['next_actionId', 'next_pointId']).copy()\n",
    "\n",
    "# Define columns to drop\n",
    "drop_cols = [\n",
    "    'rally_uid', 'serverGetPoint', 'gamePlayerId', 'gamePlayerOtherId',\n",
    "    'match_id', 'next_actionId', 'next_pointId', 'rally_outcome', 'match', 'rally_id',\n",
    "    # Drop temporary columns from EDA\n",
    "    'action_type_temp', 'rally_phase_temp', 'score_diff_temp'\n",
    "]\n",
    "features = [col for col in train_feats_df.columns if col not in drop_cols and col in test_feats_df.columns]\n",
    "\n",
    "# Identify categorical features\n",
    "categorical_features = []\n",
    "for col in features:\n",
    "    if train_feats_df[col].dtype == 'object' or 'Id' in col or 'phase' in col or col.startswith('is_'):\n",
    "        categorical_features.append(col)\n",
    "\n",
    "# Encode categorical features\n",
    "print(f\"  Encoding {len(categorical_features)} categorical features...\")\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_feats_df[col] = train_feats_df[col].astype(str)\n",
    "    test_feats_df[col] = test_feats_df[col].astype(str)\n",
    "    le.fit(pd.concat([train_feats_df[col], test_feats_df[col]]))\n",
    "    train_feats_df[col] = le.transform(train_feats_df[col])\n",
    "    test_feats_df[col] = le.transform(test_feats_df[col])\n",
    "\n",
    "# Prepare datasets\n",
    "X_next = train_feats_df.loc[train_next_df.index, features]\n",
    "groups_next = train_next_df['rally_uid']\n",
    "\n",
    "le_action = LabelEncoder()\n",
    "y_action = le_action.fit_transform(train_next_df['next_actionId'].astype(int))\n",
    "\n",
    "le_point = LabelEncoder()\n",
    "y_point = le_point.fit_transform(train_next_df['next_pointId'].astype(int))\n",
    "\n",
    "X_outcome = train_feats_df[features]\n",
    "y_outcome = train_feats_df['rally_outcome']\n",
    "groups_outcome = train_feats_df['rally_uid']\n",
    "\n",
    "test_final_rows = test_feats_df.groupby('rally_uid').tail(1)\n",
    "X_test = test_final_rows[features]\n",
    "test_rally_uids = test_final_rows['rally_uid']\n",
    "\n",
    "print(f\"âœ“ Data preparation complete\")\n",
    "print(f\"  Features: {len(features)}\")\n",
    "print(f\"  X_next: {X_next.shape}\")\n",
    "print(f\"  X_outcome: {X_outcome.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "\n",
    "# =========================================================\n",
    "# Model Training Functions\n",
    "# =========================================================\n",
    "\n",
    "def train_lgb(X, y, groups, X_test, params, cat_feats, n_splits=5):\n",
    "    \"\"\"Train LightGBM with GroupKFold cross-validation.\"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    num_class = params.get('num_class', 1)\n",
    "    is_multiclass = params['objective'] == 'multiclass'\n",
    "    \n",
    "    oof_preds = np.zeros((len(X), num_class)) if is_multiclass else np.zeros(len(X))\n",
    "    test_preds_list = []\n",
    "    \n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_tr, y_tr = X.iloc[train_idx], y[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y[val_idx]\n",
    "        \n",
    "        # Handle unseen labels\n",
    "        if is_multiclass:\n",
    "            missing = set(np.unique(y_val)) - set(np.unique(y_tr))\n",
    "            if missing:\n",
    "                add_idx = [val_idx[np.where(y_val == label)[0][0]] for label in missing]\n",
    "                X_tr = pd.concat([X_tr, X.iloc[add_idx]])\n",
    "                y_tr = np.concatenate([y_tr, y[add_idx]])\n",
    "        \n",
    "        dtrain = lgb.Dataset(X_tr, label=y_tr, categorical_feature=cat_feats)\n",
    "        dval = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_feats, reference=dtrain)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params, dtrain, valid_sets=[dval],\n",
    "            callbacks=[lgb.early_stopping(50, verbose=False), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict(X.iloc[val_idx])\n",
    "        test_preds_list.append(model.predict(X_test))\n",
    "    \n",
    "    return oof_preds, np.mean(test_preds_list, axis=0)\n",
    "\n",
    "\n",
    "def train_cat(X, y, groups, X_test, params, cat_indices, n_splits=5):\n",
    "    \"\"\"Train CatBoost with GroupKFold cross-validation.\"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    is_multiclass = 'MultiClass' in params.get('loss_function', '')\n",
    "    num_class = int(np.max(y) + 1) if is_multiclass else 1\n",
    "    \n",
    "    oof_preds = np.zeros((len(X), num_class)) if is_multiclass else np.zeros(len(X))\n",
    "    test_preds_list = []\n",
    "    \n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_tr, y_tr = X.iloc[train_idx], y[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y[val_idx]\n",
    "        \n",
    "        # Handle unseen labels\n",
    "        if is_multiclass:\n",
    "            missing = set(np.unique(y_val)) - set(np.unique(y_tr))\n",
    "            if missing:\n",
    "                add_idx = [val_idx[np.where(y_val == label)[0][0]] for label in missing]\n",
    "                X_tr = pd.concat([X_tr, X.iloc[add_idx]])\n",
    "                y_tr = np.concatenate([y_tr, y[add_idx]])\n",
    "        \n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_indices)\n",
    "        val_pool = Pool(X_val, y_val, cat_features=cat_indices)\n",
    "        \n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=0)\n",
    "        \n",
    "        if is_multiclass:\n",
    "            oof_preds[val_idx] = model.predict_proba(val_pool)\n",
    "            test_preds_list.append(model.predict_proba(X_test))\n",
    "        else:\n",
    "            oof_preds[val_idx] = model.predict_proba(val_pool)[:, 1]\n",
    "            test_preds_list.append(model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    return oof_preds, np.mean(test_preds_list, axis=0)\n",
    "\n",
    "# =========================================================\n",
    "# Dual-Engine Training with EDA-based parameters\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[5/8] Training Models (EDA-Optimized)...\")\n",
    "print(\"  ðŸŽ¯ Adjustments based on EDA:\")\n",
    "print(\"     - Lower learning rate for better generalization\")\n",
    "print(\"     - Stronger regularization (test is different)\")\n",
    "print(\"     - 50-50 blending for stability\")\n",
    "\n",
    "# EDA-Optimized: Lower learning rate, stronger regularization\n",
    "lgb_common = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 3000,\n",
    "    'learning_rate': 0.02,  # Lower for better generalization\n",
    "    'num_leaves': 24,       # Reduced complexity\n",
    "    'subsample': 0.75,      # More aggressive sampling\n",
    "    'colsample_bytree': 0.75,\n",
    "    'min_child_samples': 50,  # Stronger regularization\n",
    "    'random_state': RANDOM_SEED,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "cat_common = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.03,  # Lower for generalization\n",
    "    'depth': 6,             # Reduced depth\n",
    "    'l2_leaf_reg': 5,       # L2 regularization\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "if USE_GPU:\n",
    "    lgb_common['device'] = 'gpu'\n",
    "    cat_common.update({'task_type': 'GPU', 'devices': '0'})\n",
    "\n",
    "cat_indices = [X_next.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "# === Train Action ID ===\n",
    "print(\"\\n>> Action ID Predictor...\")\n",
    "lgb_p = {**lgb_common, 'objective': 'multiclass', \n",
    "         'num_class': len(le_action.classes_), 'metric': 'multi_logloss'}\n",
    "cat_p = {**cat_common, 'loss_function': 'MultiClass', 'eval_metric': 'MultiClass'}\n",
    "\n",
    "oof_lgb1, pred_lgb1 = train_lgb(X_next, y_action, groups_next, X_test, lgb_p, categorical_features)\n",
    "oof_cat1, pred_cat1 = train_cat(X_next, y_action, groups_next, X_test, cat_p, cat_indices)\n",
    "\n",
    "oof_blended_action = 0.5 * oof_lgb1 + 0.5 * oof_cat1\n",
    "final_proba_action = 0.5 * pred_lgb1 + 0.5 * pred_cat1\n",
    "action_f1 = f1_score(y_action, np.argmax(oof_blended_action, axis=1), average='macro')\n",
    "print(f\"   âœ“ Action OOF F1: {action_f1:.4f}\")\n",
    "\n",
    "# === Train Point ID ===\n",
    "print(\"\\n>> Point ID Predictor...\")\n",
    "lgb_p['num_class'] = len(le_point.classes_)\n",
    "\n",
    "oof_lgb2, pred_lgb2 = train_lgb(X_next, y_point, groups_next, X_test, lgb_p, categorical_features)\n",
    "oof_cat2, pred_cat2 = train_cat(X_next, y_point, groups_next, X_test, cat_p, cat_indices)\n",
    "\n",
    "oof_blended_point = 0.5 * oof_lgb2 + 0.5 * oof_cat2\n",
    "final_proba_point = 0.5 * pred_lgb2 + 0.5 * pred_cat2\n",
    "point_f1 = f1_score(y_point, np.argmax(oof_blended_point, axis=1), average='macro')\n",
    "print(f\"   âœ“ Point OOF F1: {point_f1:.4f}\")\n",
    "\n",
    "# === Train Outcome ===\n",
    "print(\"\\n>> Rally Outcome Predictor...\")\n",
    "lgb_p_bin = {**lgb_common, 'objective': 'binary', 'metric': 'auc'}\n",
    "cat_p_bin = {**cat_common, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}\n",
    "\n",
    "oof_lgb3, pred_lgb3 = train_lgb(X_outcome, y_outcome, groups_outcome, X_test, lgb_p_bin, categorical_features)\n",
    "oof_cat3, pred_cat3 = train_cat(X_outcome, y_outcome, groups_outcome, X_test, cat_p_bin, cat_indices)\n",
    "\n",
    "oof_blended_outcome = 0.5 * oof_lgb3 + 0.5 * oof_cat3\n",
    "final_proba_outcome = 0.5 * pred_lgb3 + 0.5 * pred_cat3\n",
    "outcome_auc = roc_auc_score(y_outcome, oof_blended_outcome)\n",
    "print(f\"   âœ“ Outcome OOF AUC: {outcome_auc:.4f}\")\n",
    "\n",
    "print(\"\\nâœ“ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219366a9",
   "metadata": {},
   "source": [
    "## 10. Data Preparation & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b7a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# ðŸ”„ Prediction Synchronization\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[6/8] Synchronizing Predictions...\")\n",
    "\n",
    "def synchronize_endings(prob_act, prob_pt, le_act, le_pt, threshold=0.5):\n",
    "    \"\"\"Synchronize action and point predictions for rally endings.\"\"\"\n",
    "    try:\n",
    "        act_neg1_idx = list(le_act.classes_).index(-1)\n",
    "        pt_neg1_idx = list(le_pt.classes_).index(-1)\n",
    "        \n",
    "        p_end = (prob_act[:, act_neg1_idx] + prob_pt[:, pt_neg1_idx]) / 2\n",
    "        \n",
    "        prob_act_mod, prob_pt_mod = prob_act.copy(), prob_pt.copy()\n",
    "        prob_act_mod[p_end >= threshold, act_neg1_idx] = 2.0\n",
    "        prob_pt_mod[p_end >= threshold, pt_neg1_idx] = 2.0\n",
    "        prob_act_mod[p_end < threshold, act_neg1_idx] = 0.0\n",
    "        prob_pt_mod[p_end < threshold, pt_neg1_idx] = 0.0\n",
    "        \n",
    "        synced_count = (p_end >= threshold).sum()\n",
    "        print(f\"  âœ“ Synchronized {synced_count} endings\")\n",
    "        \n",
    "        return (le_act.inverse_transform(np.argmax(prob_act_mod, axis=1)),\n",
    "                le_pt.inverse_transform(np.argmax(prob_pt_mod, axis=1)))\n",
    "    except ValueError:\n",
    "        print(\"  âš  Warning: -1 label not found\")\n",
    "        return (le_act.inverse_transform(np.argmax(prob_act, axis=1)),\n",
    "                le_pt.inverse_transform(np.argmax(prob_pt, axis=1)))\n",
    "\n",
    "final_action, final_point = synchronize_endings(\n",
    "    final_proba_action, final_proba_point, le_action, le_point\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae61273",
   "metadata": {},
   "source": [
    "## 11. Synchronize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# ðŸ“¤ Generate Submission\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[7/8] Generating Submission...\")\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'rally_uid': test_rally_uids,\n",
    "    'serverGetPoint': final_proba_outcome,\n",
    "    'pointId': final_point,\n",
    "    'actionId': final_action\n",
    "})\n",
    "\n",
    "# Merge with submission template\n",
    "final_submission = pd.merge(submission_df[['rally_uid']], submission, on='rally_uid', how='left')\n",
    "\n",
    "# Fill missing values\n",
    "final_submission.fillna({'serverGetPoint': 0.5}, inplace=True)\n",
    "valid_action_mode = train_df['actionId'].mode()[0]\n",
    "valid_point_mode = train_df['pointId'].mode()[0]\n",
    "final_submission['actionId'] = final_submission['actionId'].fillna(valid_action_mode).astype(int)\n",
    "final_submission['pointId'] = final_submission['pointId'].fillna(valid_point_mode).astype(int)\n",
    "\n",
    "print(f\"âœ“ Submission created: {final_submission.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd024ee9",
   "metadata": {},
   "source": [
    "## 12. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1fa086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "output_file = '../submissions/submission_gold_eda.csv'\n",
    "final_submission.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"  âœ“ Saved to '{output_file}'\")\n",
    "print(f\"\\n  Summary:\")\n",
    "print(f\"    Total predictions: {len(final_submission)}\")\n",
    "print(f\"    Action -1 (end): {(final_submission['actionId'] == -1).sum()}\")\n",
    "print(f\"    Point -1 (end): {(final_submission['pointId'] == -1).sum()}\")\n",
    "print(f\"    Mean serverGetPoint: {final_submission['serverGetPoint'].mean():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… EDA-OPTIMIZED TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nðŸ“Š OOF Performance:\")\n",
    "print(f\"  Action F1:   {action_f1:.4f}\")\n",
    "print(f\"  Point F1:    {point_f1:.4f}\")\n",
    "print(f\"  Outcome AUC: {outcome_auc:.4f}\")\n",
    "print(f\"\\nðŸŽ¯ EDA-Based Optimizations Applied:\")\n",
    "print(f\"  âœ“ Early-phase focused features (test has 32.7% serves vs 15.9% train)\")\n",
    "print(f\"  âœ“ Hand-spin-strength combinations (aligned with test distribution)\")\n",
    "print(f\"  âœ“ Reduced Lag-2 dependency (test rallies are shorter)\")\n",
    "print(f\"  âœ“ Stronger regularization for domain adaptation\")\n",
    "print(f\"  âœ“ 50-50 blending for stability\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
