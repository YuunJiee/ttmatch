{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6eb2d5",
   "metadata": {},
   "source": [
    "# üèì Table Tennis Match Prediction - V6 (Competition Submission)\n",
    "\n",
    "**Version**: V6 - Rally Context Features (Overfitted)\n",
    "\n",
    "**Performance**: \n",
    "- Private Score: 0.3419 ‚ùå\n",
    "- Public Score: 0.3698\n",
    "- Delta: -0.0279 (overfitting to public test)\n",
    "\n",
    "**Problems**:\n",
    "1. ‚ùå `rally_serve_action/point`: Information leakage from first stroke\n",
    "2. ‚ùå `is_deuce`, `is_server`: Training-specific patterns\n",
    "3. ‚ùå 80-20 ensemble: Unbalanced blend\n",
    "4. ‚ùå Sample weighting: Reduced generalization\n",
    "\n",
    "**Note**: This version is included for educational purposes to show what NOT to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaca30f",
   "metadata": {},
   "source": [
    "## 1. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cfe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Global Configuration\n",
    "# =========================================================\n",
    "USE_GPU = True  # Set to True if GPU available\n",
    "N_FOLDS = 5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# =========================================================\n",
    "# 1. Setup & Import\n",
    "# =========================================================\n",
    "# !pip -q install lightgbm catboost pandas numpy scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Imports complete\")\n",
    "print(f\"LightGBM version: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0826e20e",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb07f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 2. Load Data\n",
    "# =========================================================\n",
    "try:\n",
    "    print(\"[2/8] Loading data...\")\n",
    "    train_df = pd.read_csv(\"../data/train.csv\")\n",
    "    test_df = pd.read_csv(\"../data/test.csv\")\n",
    "    submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "    print(\"‚úì Loaded from ../data/\")\n",
    "except:\n",
    "    try:\n",
    "        train_df = pd.read_csv(\"data/train.csv\")\n",
    "        test_df = pd.read_csv(\"data/test.csv\")\n",
    "        submission_df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "        print(\"‚úì Loaded from data/\")\n",
    "    except:\n",
    "        print(\"‚ùå Error: Data files not found\")\n",
    "        raise\n",
    "\n",
    "print(f\"Train: {train_df.shape}, Test: {test_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5e2aa1",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering (V6 - Rally Context Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc804a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 3. Feature Engineering (V6: Rally Context Features)\n",
    "# =========================================================\n",
    "print(\"[3/8] Feature Engineering (V6: Rally Context)...\")\n",
    "\n",
    "def get_rally_phase(n):\n",
    "    if n == 1: return 0      # Serve\n",
    "    elif n == 2: return 1    # Return\n",
    "    elif n <= 4: return 2    # Early rally\n",
    "    else: return 3           # Extended rally\n",
    "\n",
    "def create_features(df):\n",
    "    df_feats = df.copy()\n",
    "    \n",
    "    # --- Basic Features ---\n",
    "    df_feats['rally_phase'] = df_feats['strickNumber'].apply(get_rally_phase)\n",
    "    action_map = {\n",
    "        1: 'Attack', 2: 'Attack', 3: 'Attack', 4: 'Attack', 5: 'Attack', 6: 'Attack', 7: 'Attack',\n",
    "        8: 'Control', 9: 'Control', 10: 'Control', 11: 'Control',\n",
    "        12: 'Defensive', 13: 'Defensive', 14: 'Defensive',\n",
    "        15: 'Serve', 16: 'Serve', 17: 'Serve', 18: 'Serve',\n",
    "        0: 'Zero', -1: 'Zero'\n",
    "    }\n",
    "    df_feats['action_type'] = df_feats['actionId'].map(action_map).fillna('Zero')\n",
    "    \n",
    "    if 'scoreSelf' in df_feats.columns and 'scoreOther' in df_feats.columns:\n",
    "        df_feats['score_diff'] = df_feats['scoreSelf'] - df_feats['scoreOther']\n",
    "        df_feats['is_deuce'] = ((df_feats['scoreSelf'] >= 9) & (df_feats['scoreOther'] >= 9) & (df_feats['score_diff'].abs() <= 2)).astype(int)\n",
    "    if 'serveId' in df_feats.columns and 'gamePlayerId' in df_feats.columns:\n",
    "        df_feats['is_server'] = (df_feats['serveId'] == df_feats['gamePlayerId']).astype(int)\n",
    "\n",
    "    # --- Rally Context Features (INFORMATION LEAKAGE!) ---\n",
    "    # ‚ùå PROBLEM: Propagates first stroke info to entire rally\n",
    "    serve_info = df_feats[df_feats['strickNumber'] == 1][['rally_uid', 'actionId', 'pointId']].copy()\n",
    "    serve_info.columns = ['rally_uid', 'rally_serve_action', 'rally_serve_point']\n",
    "    df_feats = pd.merge(df_feats, serve_info, on='rally_uid', how='left')\n",
    "    df_feats['rally_serve_action'] = df_feats['rally_serve_action'].fillna(-999).astype(int)\n",
    "    df_feats['rally_serve_point'] = df_feats['rally_serve_point'].fillna(-999).astype(int)\n",
    "\n",
    "    # --- Lag Features ---\n",
    "    lag1_cols = ['strickId', 'handId', 'strengthId', 'spinId', 'pointId', 'actionId', 'positionId', 'action_type']\n",
    "    for col in lag1_cols:\n",
    "        df_feats[f'prev_{col}'] = df_feats.groupby('rally_uid')[col].shift(1)\n",
    "    lag2_cols = ['actionId', 'pointId', 'action_type']\n",
    "    for col in lag2_cols:\n",
    "        df_feats[f'prev2_{col}'] = df_feats.groupby('rally_uid')[col].shift(2)\n",
    "\n",
    "    # --- Interaction Features ---\n",
    "    df_feats['prev_hand_spin'] = df_feats['prev_handId'].astype(str) + '_' + df_feats['prev_spinId'].astype(str)\n",
    "    df_feats['prev_action_point'] = df_feats['prev_actionId'].astype(str) + '_' + df_feats['prev_pointId'].astype(str)\n",
    "\n",
    "    # --- Fill Missing Values ---\n",
    "    for col in df_feats.columns:\n",
    "        if 'prev' in col: \n",
    "            df_feats[col] = df_feats[col].replace(['nan_nan', 'nan', '<NA>', '<NA>_<NA>'], np.nan)\n",
    "        if col.startswith('prev'):\n",
    "            df_feats[col] = df_feats[col].fillna('None' if df_feats[col].dtype == 'object' else -999)\n",
    "\n",
    "    return df_feats\n",
    "\n",
    "train_feats_df = create_features(train_df)\n",
    "test_feats_df = create_features(test_df)\n",
    "\n",
    "print(f\"‚úì Train: {train_feats_df.shape}, Test: {test_feats_df.shape}\")\n",
    "print(f\"‚ö†Ô∏è Warning: Includes rally_serve_action/point (INFORMATION LEAKAGE!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214fbf9",
   "metadata": {},
   "source": [
    "## 4. Prepare Training Data & Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 4. Prepare Training Data\n",
    "# =========================================================\n",
    "print(\"[4/8] Preparing Datasets...\")\n",
    "\n",
    "# Create target variables\n",
    "train_feats_df['next_actionId'] = train_feats_df.groupby('rally_uid')['actionId'].shift(-1)\n",
    "train_feats_df['next_pointId'] = train_feats_df.groupby('rally_uid')['pointId'].shift(-1)\n",
    "train_feats_df['rally_outcome'] = train_feats_df['serverGetPoint']\n",
    "\n",
    "train_next_df = train_feats_df.dropna(subset=['next_actionId', 'next_pointId']).copy()\n",
    "\n",
    "# Define features\n",
    "drop_cols = ['rally_uid', 'serverGetPoint', 'gamePlayerId', 'gamePlayerOtherId', 'match_id', \n",
    "             'next_actionId', 'next_pointId', 'rally_outcome', 'match', 'rally_id']\n",
    "features = [col for col in train_feats_df.columns if col not in drop_cols]\n",
    "\n",
    "# Identify categorical features\n",
    "categorical_features = []\n",
    "for col in features:\n",
    "    if train_feats_df[col].dtype == 'object' or 'Id' in col or 'phase' in col or 'is_' in col or 'serve_' in col:\n",
    "        categorical_features.append(col)\n",
    "\n",
    "# Encode categorical features\n",
    "print(f\"Encoding {len(categorical_features)} categorical features...\")\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_feats_df[col] = train_feats_df[col].astype(str)\n",
    "    test_feats_df[col] = test_feats_df[col].astype(str)\n",
    "    le.fit(pd.concat([train_feats_df[col], test_feats_df[col]]))\n",
    "    train_feats_df[col] = le.transform(train_feats_df[col])\n",
    "    test_feats_df[col] = le.transform(test_feats_df[col])\n",
    "\n",
    "# Prepare datasets\n",
    "X_next = train_feats_df.loc[train_next_df.index, features]\n",
    "groups_next = train_next_df['rally_uid']\n",
    "\n",
    "le_action = LabelEncoder()\n",
    "y_action = le_action.fit_transform(train_next_df['next_actionId'].astype(int))\n",
    "\n",
    "le_point = LabelEncoder()\n",
    "y_point = le_point.fit_transform(train_next_df['next_pointId'].astype(int))\n",
    "\n",
    "X_outcome = train_feats_df[features]\n",
    "y_outcome = train_feats_df['rally_outcome']\n",
    "groups_outcome = train_feats_df['rally_uid']\n",
    "\n",
    "# Test data (last row of each rally)\n",
    "test_final_rows = test_feats_df.groupby('rally_uid').tail(1)\n",
    "X_test = test_final_rows[features]\n",
    "test_rally_uids = test_final_rows['rally_uid']\n",
    "\n",
    "print(f\"‚úì X_next: {X_next.shape}, X_outcome: {X_outcome.shape}, X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61561a42",
   "metadata": {},
   "source": [
    "## 5. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 5. Training Functions\n",
    "# =========================================================\n",
    "def train_lgb(X, y, groups, X_test, params, cat_feats, n_splits=5):\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    num_class = params.get('num_class', 1)\n",
    "    is_multiclass = params['objective'] == 'multiclass'\n",
    "    oof_preds = np.zeros((len(X), num_class)) if is_multiclass else np.zeros(len(X))\n",
    "    test_preds_list = []\n",
    "    \n",
    "    # ‚ùå PROBLEM: Sample weighting reduces generalization\n",
    "    if is_multiclass:\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y)\n",
    "    else:\n",
    "        sample_weights = np.ones(len(y))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
    "        X_tr, y_tr = X.iloc[train_idx], y[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y[val_idx]\n",
    "        w_tr = sample_weights[train_idx]\n",
    "        \n",
    "        if is_multiclass:\n",
    "             missing = set(np.unique(y_val)) - set(np.unique(y_tr))\n",
    "             if missing:\n",
    "                 add_idx = [val_idx[np.where(y_val == label)[0][0]] for label in missing]\n",
    "                 X_tr = pd.concat([X_tr, X.iloc[add_idx]])\n",
    "                 y_tr = np.concatenate([y_tr, y[add_idx]])\n",
    "                 w_tr = np.concatenate([w_tr, sample_weights[add_idx]])\n",
    "        \n",
    "        dtrain = lgb.Dataset(X_tr, label=y_tr, weight=w_tr, categorical_feature=cat_feats)\n",
    "        dval = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_feats, reference=dtrain)\n",
    "        model = lgb.train(params, dtrain, valid_sets=[dval], \n",
    "                         callbacks=[lgb.early_stopping(50, verbose=False), lgb.log_evaluation(0)])\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict(X.iloc[val_idx])\n",
    "        test_preds_list.append(model.predict(X_test))\n",
    "            \n",
    "    return oof_preds, np.mean(test_preds_list, axis=0)\n",
    "\n",
    "def train_cat(X, y, groups, X_test, params, cat_indices, n_splits=5):\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    is_multiclass = 'MultiClass' in params.get('loss_function', '')\n",
    "    num_class = int(np.max(y) + 1) if is_multiclass else 1\n",
    "    oof_preds = np.zeros((len(X), num_class)) if is_multiclass else np.zeros(len(X))\n",
    "    test_preds_list = []\n",
    "    \n",
    "    # ‚ùå PROBLEM: Auto class weights\n",
    "    if is_multiclass: params['auto_class_weights'] = 'Balanced'\n",
    "    \n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_tr, y_tr = X.iloc[train_idx], y[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y[val_idx]\n",
    "        \n",
    "        if is_multiclass:\n",
    "             missing = set(np.unique(y_val)) - set(np.unique(y_tr))\n",
    "             if missing:\n",
    "                 add_idx = [val_idx[np.where(y_val == label)[0][0]] for label in missing]\n",
    "                 X_tr = pd.concat([X_tr, X.iloc[add_idx]])\n",
    "                 y_tr = np.concatenate([y_tr, y[add_idx]])\n",
    "                 \n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_indices)\n",
    "        val_pool = Pool(X_val, y_val, cat_features=cat_indices)\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=0)\n",
    "        \n",
    "        if is_multiclass:\n",
    "            oof_preds[val_idx] = model.predict_proba(val_pool)\n",
    "            test_preds_list.append(model.predict_proba(X_test))\n",
    "        else:\n",
    "            oof_preds[val_idx] = model.predict_proba(val_pool)[:, 1]\n",
    "            test_preds_list.append(model.predict_proba(X_test)[:, 1])\n",
    "            \n",
    "    return oof_preds, np.mean(test_preds_list, axis=0)\n",
    "\n",
    "print(\"‚úÖ Training functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1674f",
   "metadata": {},
   "source": [
    "## 6. Train Models (Dual-Engine: 80% LGBM + 20% CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2af671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 6. Train Models (80% LGBM + 20% CatBoost)\n",
    "# =========================================================\n",
    "print(\"\\n[5/8] Training Dual-Engine Models...\")\n",
    "\n",
    "# Model parameters\n",
    "lgb_common = {\n",
    "    'boosting_type': 'gbdt', 'n_estimators': 3000, 'learning_rate': 0.03, \n",
    "    'num_leaves': 31, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "    'random_state': RANDOM_SEED, 'n_jobs': -1, 'verbose': -1\n",
    "}\n",
    "cat_common = {\n",
    "    'iterations': 2000, 'learning_rate': 0.05, 'depth': 7, \n",
    "    'random_seed': RANDOM_SEED, 'verbose': 0\n",
    "}\n",
    "\n",
    "if USE_GPU:\n",
    "    lgb_common['device'] = 'gpu'\n",
    "    cat_common.update({'task_type': 'GPU', 'devices': '0'})\n",
    "\n",
    "cat_indices = [X_next.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "# ‚ö†Ô∏è PROBLEM: Unbalanced ensemble (80-20)\n",
    "print(\"‚ö†Ô∏è Using 80% LGBM + 20% CatBoost (unbalanced)\")\n",
    "\n",
    "# --- Action ID ---\n",
    "print(\"\\n>> Action ID...\")\n",
    "lgb_p = {**lgb_common, 'objective': 'multiclass', 'num_class': len(le_action.classes_), 'metric': 'multi_logloss'}\n",
    "cat_p = {**cat_common, 'loss_function': 'MultiClass', 'eval_metric': 'MultiClass'}\n",
    "\n",
    "oof_lgb1, pred_lgb1 = train_lgb(X_next, y_action, groups_next, X_test, lgb_p, categorical_features)\n",
    "oof_cat1, pred_cat1 = train_cat(X_next, y_action, groups_next, X_test, cat_p, cat_indices)\n",
    "\n",
    "final_proba_action = 0.8 * pred_lgb1 + 0.2 * pred_cat1\n",
    "oof_blended_action = 0.8 * oof_lgb1 + 0.2 * oof_cat1\n",
    "print(f\"   OOF F1: {f1_score(y_action, np.argmax(oof_blended_action, axis=1), average='macro'):.4f}\")\n",
    "\n",
    "# --- Point ID ---\n",
    "print(\"\\n>> Point ID...\")\n",
    "lgb_p['num_class'] = len(le_point.classes_)\n",
    "\n",
    "oof_lgb2, pred_lgb2 = train_lgb(X_next, y_point, groups_next, X_test, lgb_p, categorical_features)\n",
    "oof_cat2, pred_cat2 = train_cat(X_next, y_point, groups_next, X_test, cat_p, cat_indices)\n",
    "\n",
    "final_proba_point = 0.8 * pred_lgb2 + 0.2 * pred_cat2\n",
    "oof_blended_point = 0.8 * oof_lgb2 + 0.2 * oof_cat2\n",
    "print(f\"   OOF F1: {f1_score(y_point, np.argmax(oof_blended_point, axis=1), average='macro'):.4f}\")\n",
    "\n",
    "# --- Outcome ---\n",
    "print(\"\\n>> Rally Outcome...\")\n",
    "lgb_p_bin = {**lgb_common, 'objective': 'binary', 'metric': 'auc'}\n",
    "cat_p_bin = {**cat_common, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}\n",
    "\n",
    "oof_lgb3, pred_lgb3 = train_lgb(X_outcome, y_outcome, groups_outcome, X_test, lgb_p_bin, categorical_features)\n",
    "oof_cat3, pred_cat3 = train_cat(X_outcome, y_outcome, groups_outcome, X_test, cat_p_bin, cat_indices)\n",
    "\n",
    "final_proba_outcome = 0.7 * pred_lgb3 + 0.3 * pred_cat3\n",
    "oof_blended_outcome = 0.7 * oof_lgb3 + 0.3 * oof_cat3\n",
    "print(f\"   OOF AUC: {roc_auc_score(y_outcome, oof_blended_outcome):.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624cd1e",
   "metadata": {},
   "source": [
    "## 7. Synchronize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55afdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 7. Synchronize Predictions\n",
    "# =========================================================\n",
    "print(\"\\n[6/8] Synchronizing Predictions...\")\n",
    "\n",
    "def synchronize_endings_strict(prob_act, prob_pt, le_act, le_pt, threshold=0.5):\n",
    "    \"\"\"Synchronize action/point predictions for rally endings\"\"\"\n",
    "    try:\n",
    "        act_neg1_idx = list(le_act.classes_).index(-1)\n",
    "        pt_neg1_idx = list(le_pt.classes_).index(-1)\n",
    "        p_end = (prob_act[:, act_neg1_idx] + prob_pt[:, pt_neg1_idx]) / 2\n",
    "        \n",
    "        prob_act_mod, prob_pt_mod = prob_act.copy(), prob_pt.copy()\n",
    "        prob_act_mod[p_end >= threshold, act_neg1_idx] = 2.0\n",
    "        prob_pt_mod[p_end >= threshold, pt_neg1_idx] = 2.0\n",
    "        prob_act_mod[p_end < threshold, act_neg1_idx] = 0.0\n",
    "        prob_pt_mod[p_end < threshold, pt_neg1_idx] = 0.0\n",
    "        \n",
    "        print(f\"‚úì Synced {(p_end >= threshold).sum()} rows to END\")\n",
    "        return le_act.inverse_transform(np.argmax(prob_act_mod, axis=1)), \\\n",
    "               le_pt.inverse_transform(np.argmax(prob_pt_mod, axis=1))\n",
    "    except:\n",
    "        print(\"‚úó Could not find -1 class, skipping sync\")\n",
    "        return le_act.inverse_transform(np.argmax(prob_act, axis=1)), \\\n",
    "               le_pt.inverse_transform(np.argmax(prob_pt, axis=1))\n",
    "\n",
    "final_action, final_point = synchronize_endings_strict(\n",
    "    final_proba_action, final_proba_point, le_action, le_point\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210bea3f",
   "metadata": {},
   "source": [
    "## 8. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6791b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 8. Generate Submission\n",
    "# =========================================================\n",
    "print(\"\\n[7/8] Generating Submission...\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'rally_uid': test_rally_uids, \n",
    "    'serverGetPoint': final_proba_outcome, \n",
    "    'pointId': final_point, \n",
    "    'actionId': final_action\n",
    "})\n",
    "\n",
    "final_submission = pd.merge(submission_df[['rally_uid']], submission, on='rally_uid', how='left')\n",
    "final_submission.fillna({'serverGetPoint': 0.5}, inplace=True)\n",
    "\n",
    "valid_action_mode = train_df['actionId'].mode()[0]\n",
    "valid_point_mode = train_df['pointId'].mode()[0]\n",
    "final_submission['actionId'] = final_submission['actionId'].fillna(valid_action_mode).astype(int)\n",
    "final_submission['pointId'] = final_submission['pointId'].fillna(valid_point_mode).astype(int)\n",
    "\n",
    "final_submission.to_csv('../submissions/submission_v6.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Submission saved to: ../submissions/submission_v6.csv\")\n",
    "print(f\"\\nShape: {final_submission.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(final_submission.head())\n",
    "print(\"\\n‚ö†Ô∏è Warning: This version overfits to public test!\")\n",
    "print(\"   Use main_gold.ipynb or main_gold_eda.ipynb for better generalization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293b68e",
   "metadata": {},
   "source": [
    "## 10. Summary: What Went Wrong in V6?\n",
    "\n",
    "### ‚ùå Problem 1: Rally Context Information Leakage\n",
    "```python\n",
    "df['rally_serve_action'] = df.groupby('rally_uid')['actionId'].transform('first')\n",
    "df['rally_serve_point'] = df.groupby('rally_uid')['pointId'].transform('first')\n",
    "```\n",
    "**Issue**: Propagates first stroke information to entire rally\n",
    "**Impact**: Model learns to \"peek\" at rally start, doesn't generalize\n",
    "\n",
    "### ‚ùå Problem 2: Training-Specific Features\n",
    "```python\n",
    "df['is_deuce'] = ((df['server_score'] >= 10) & (df['receiver_score'] >= 10)).astype(int)\n",
    "df['is_server'] = (df['stroke_number'] % 2 == 0).astype(int)\n",
    "```\n",
    "**Issue**: Patterns specific to training set distribution\n",
    "**Impact**: Overfits to training patterns that differ in test\n",
    "\n",
    "### ‚ùå Problem 3: Unbalanced Ensemble\n",
    "```python\n",
    "BLEND_RATIO = 0.8  # 80% LGBM, 20% CatBoost\n",
    "```\n",
    "**Issue**: Over-relies on one model, reduces diversity\n",
    "**Impact**: Less stable predictions, worse generalization\n",
    "\n",
    "### ‚ùå Problem 4: Sample Weighting\n",
    "```python\n",
    "sample_weights = compute_sample_weight('balanced', y_tr)\n",
    "```\n",
    "**Issue**: Forces class balance when test distribution may differ\n",
    "**Impact**: Model optimizes wrong objective\n",
    "\n",
    "### üìä Final Results\n",
    "- **Public Score**: 0.3698 (looked good!)\n",
    "- **Private Score**: 0.3419 (reality check)\n",
    "- **Delta**: -0.0279 (-7.5% drop)\n",
    "\n",
    "### ‚úÖ Lessons Learned\n",
    "1. **Avoid Information Leakage**: Features should only use past information\n",
    "2. **Trust Cross-Validation**: OOF scores are better indicators than public LB\n",
    "3. **Simple Features Win**: Complexity often hurts generalization\n",
    "4. **Balanced Ensembles**: Equal weighting usually works best\n",
    "5. **Distribution Awareness**: Understand train/test differences\n",
    "\n",
    "### üîó Better Alternatives\n",
    "- **main_gold.ipynb**: Clean baseline (0.3574 private, +15.5 points)\n",
    "- **main_gold_eda.ipynb**: EDA-optimized (0.3596 private, +17.7 points)\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This notebook is preserved for educational purposes to demonstrate common pitfalls in machine learning competitions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
