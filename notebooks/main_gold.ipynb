{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3c97d5",
   "metadata": {},
   "source": [
    "# üèì Table Tennis Match Prediction - Gold (Baseline)\n",
    "\n",
    "**Version**: Gold - Clean Baseline\n",
    "\n",
    "**Performance**: \n",
    "- Private Score: 0.3574 ‚úÖ\n",
    "- Public Score: 0.3205\n",
    "- Delta: +0.0369 (good generalization)\n",
    "\n",
    "**Key Improvements over V6**:\n",
    "1. ‚úÖ No information leakage (removed `rally_serve_action/point`)\n",
    "2. ‚úÖ Cleaner features (removed `is_deuce`, `is_server`)\n",
    "3. ‚úÖ Balanced ensemble (50-50 LGBM + CatBoost)\n",
    "4. ‚úÖ No sample weighting (better generalization)\n",
    "5. ‚úÖ Added `prev_action_phase` (contextual feature without leakage)\n",
    "\n",
    "**Note**: This version provides a solid baseline with better generalization than V6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb62e1f",
   "metadata": {},
   "source": [
    "## 1. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e300029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# üîß SECTION 1: Configuration & Setup\n",
    "# =========================================================\n",
    "\n",
    "# Global Configuration\n",
    "USE_GPU = True      # Set to True if GPU is available\n",
    "N_FOLDS = 5          # 5-fold cross-validation\n",
    "RANDOM_SEED = 42     # Fixed random seed\n",
    "\n",
    "# Install required libraries\n",
    "print(\"[1/8] Installing Libraries...\")\n",
    "# Uncomment the next line if running in Colab or need to install packages\n",
    "# !pip -q install lightgbm catboost pandas numpy scikit-learn\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import warnings\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Python Version: {sys.version.split(' ')[0]}\")\n",
    "print(f\"LightGBM Version: {lgb.__version__}\")\n",
    "print(f\"GPU Enabled: {USE_GPU}\")\n",
    "print(f\"Random Seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e624b6",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# üìä SECTION 2: Data Loading\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[2/8] Loading data...\")\n",
    "\n",
    "try:\n",
    "    # Try loading from parent data/ directory (when running from notebooks/)\n",
    "    train_df = pd.read_csv(\"../data/train.csv\")\n",
    "    test_df = pd.read_csv(\"../data/test.csv\")\n",
    "    submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "    print(f\"‚úì Data loaded from ../data/ directory\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        # Try loading from local data/ directory\n",
    "        train_df = pd.read_csv(\"data/train.csv\")\n",
    "        test_df = pd.read_csv(\"data/test.csv\")\n",
    "        submission_df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "        print(f\"‚úì Data loaded from data/ directory\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Error: Data files not found.\")\n",
    "        print(\"Please ensure train.csv, test.csv, and sample_submission.csv are in data/ directory.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "print(f\"  Train shape: {train_df.shape}\")\n",
    "print(f\"  Test shape: {test_df.shape}\")\n",
    "print(f\"  Submission shape: {submission_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec6f5c",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering (Gold Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# üî® SECTION 3: Feature Engineering (Gold Version)\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[3/8] Feature Engineering (Gold Version)...\")\n",
    "\n",
    "def get_rally_phase(n):\n",
    "    \"\"\"Categorize rally by stroke number.\"\"\"\n",
    "    if n == 1: return 0      # Serve\n",
    "    elif n == 2: return 1    # Return\n",
    "    elif n <= 4: return 2    # Early rally\n",
    "    else: return 3           # Extended rally\n",
    "\n",
    "def create_features_gold(df):\n",
    "    \"\"\"\n",
    "    Create Gold version features.\n",
    "    \n",
    "    Key differences from V6:\n",
    "    - NO rally_serve_action/point (avoids information leakage)\n",
    "    - NO is_deuce (too specific)\n",
    "    - NO is_server (overfits to training distribution)\n",
    "    - YES prev_action_phase (better generalization)\n",
    "    \"\"\"\n",
    "    df_feats = df.copy()\n",
    "    \n",
    "    # === 1. Basic Features ===\n",
    "    df_feats['rally_phase'] = df_feats['strickNumber'].apply(get_rally_phase)\n",
    "    \n",
    "    action_map = {\n",
    "        1: 'Attack', 2: 'Attack', 3: 'Attack', 4: 'Attack', 5: 'Attack', 6: 'Attack', 7: 'Attack',\n",
    "        8: 'Control', 9: 'Control', 10: 'Control', 11: 'Control',\n",
    "        12: 'Defensive', 13: 'Defensive', 14: 'Defensive',\n",
    "        15: 'Serve', 16: 'Serve', 17: 'Serve', 18: 'Serve',\n",
    "        0: 'Zero', -1: 'Zero'\n",
    "    }\n",
    "    df_feats['action_type'] = df_feats['actionId'].map(action_map).fillna('Zero')\n",
    "    \n",
    "    # Score features\n",
    "    if 'scoreSelf' in df_feats.columns and 'scoreOther' in df_feats.columns:\n",
    "        df_feats['score_diff'] = df_feats['scoreSelf'] - df_feats['scoreOther']\n",
    "    \n",
    "    # === 2. Lag-1 Features ===\n",
    "    lag1_cols = ['strickId', 'handId', 'strengthId', 'spinId', 'pointId', \n",
    "                 'actionId', 'positionId', 'action_type']\n",
    "    for col in lag1_cols:\n",
    "        df_feats[f'prev_{col}'] = df_feats.groupby('rally_uid')[col].shift(1)\n",
    "    \n",
    "    # === 3. Lag-2 Features ===\n",
    "    lag2_cols = ['actionId', 'pointId', 'action_type']\n",
    "    for col in lag2_cols:\n",
    "        df_feats[f'prev2_{col}'] = df_feats.groupby('rally_uid')[col].shift(2)\n",
    "    \n",
    "    # === 4. Tactical Combinations ===\n",
    "    df_feats['prev_hand_spin'] = (\n",
    "        df_feats['prev_handId'].astype(str) + '_' + df_feats['prev_spinId'].astype(str)\n",
    "    )\n",
    "    df_feats['prev_action_point'] = (\n",
    "        df_feats['prev_actionId'].astype(str) + '_' + df_feats['prev_pointId'].astype(str)\n",
    "    )\n",
    "    # üåü Gold's key feature: combines previous action with current rally phase\n",
    "    df_feats['prev_action_phase'] = (\n",
    "        df_feats['prev_actionId'].astype(str) + '_ph' + df_feats['rally_phase'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # === 5. Fill Missing Values ===\n",
    "    for col in df_feats.columns:\n",
    "        if 'prev' in col:\n",
    "            df_feats[col] = df_feats[col].replace(\n",
    "                ['nan_nan', 'nan', '<NA>', '<NA>_<NA>'], np.nan\n",
    "            )\n",
    "        \n",
    "        if col.startswith('prev'):\n",
    "            if df_feats[col].dtype == 'object':\n",
    "                df_feats[col] = df_feats[col].fillna('None')\n",
    "            else:\n",
    "                df_feats[col] = df_feats[col].fillna(-999)\n",
    "    \n",
    "    return df_feats\n",
    "\n",
    "# Create features\n",
    "train_feats_df = create_features_gold(train_df)\n",
    "test_feats_df = create_features_gold(test_df)\n",
    "\n",
    "print(f\"‚úì Created {len(train_feats_df.columns)} features\")\n",
    "print(f\"  Train features shape: {train_feats_df.shape}\")\n",
    "print(f\"  Test features shape: {test_feats_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2c813",
   "metadata": {},
   "source": [
    "## 4. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e280c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# üéØ SECTION 4: Data Preparation\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[4/8] Preparing Datasets...\")\n",
    "\n",
    "# Create target variables\n",
    "train_feats_df['next_actionId'] = train_feats_df.groupby('rally_uid')['actionId'].shift(-1)\n",
    "train_feats_df['next_pointId'] = train_feats_df.groupby('rally_uid')['pointId'].shift(-1)\n",
    "train_feats_df['rally_outcome'] = train_feats_df['serverGetPoint']\n",
    "\n",
    "# Filter rows with valid next actions\n",
    "train_next_df = train_feats_df.dropna(subset=['next_actionId', 'next_pointId']).copy()\n",
    "\n",
    "# Define columns to drop\n",
    "drop_cols = [\n",
    "    'rally_uid', 'serverGetPoint', 'gamePlayerId', 'gamePlayerOtherId',\n",
    "    'match_id', 'next_actionId', 'next_pointId', 'rally_outcome', 'match', 'rally_id'\n",
    "]\n",
    "features = [col for col in train_feats_df.columns if col not in drop_cols]\n",
    "\n",
    "# Identify categorical features\n",
    "categorical_features = []\n",
    "for col in features:\n",
    "    if train_feats_df[col].dtype == 'object' or 'Id' in col or 'phase' in col:\n",
    "        categorical_features.append(col)\n",
    "\n",
    "# Encode categorical features\n",
    "print(f\"  Encoding {len(categorical_features)} categorical features...\")\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_feats_df[col] = train_feats_df[col].astype(str)\n",
    "    test_feats_df[col] = test_feats_df[col].astype(str)\n",
    "    le.fit(pd.concat([train_feats_df[col], test_feats_df[col]]))\n",
    "    train_feats_df[col] = le.transform(train_feats_df[col])\n",
    "    test_feats_df[col] = le.transform(test_feats_df[col])\n",
    "\n",
    "# Prepare datasets\n",
    "X_next = train_feats_df.loc[train_next_df.index, features]\n",
    "groups_next = train_next_df['rally_uid']\n",
    "\n",
    "le_action = LabelEncoder()\n",
    "y_action = le_action.fit_transform(train_next_df['next_actionId'].astype(int))\n",
    "\n",
    "le_point = LabelEncoder()\n",
    "y_point = le_point.fit_transform(train_next_df['next_pointId'].astype(int))\n",
    "\n",
    "X_outcome = train_feats_df[features]\n",
    "y_outcome = train_feats_df['rally_outcome']\n",
    "groups_outcome = train_feats_df['rally_uid']\n",
    "\n",
    "test_final_rows = test_feats_df.groupby('rally_uid').tail(1)\n",
    "X_test = test_final_rows[features]\n",
    "test_rally_uids = test_final_rows['rally_uid']\n",
    "\n",
    "print(f\"‚úì X_next shape: {X_next.shape}\")\n",
    "print(f\"‚úì X_outcome shape: {X_outcome.shape}\")\n",
    "print(f\"‚úì X_test shape: {X_test.shape}\")\n",
    "print(f\"‚úì Number of features: {len(features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8bfb85",
   "metadata": {},
   "source": [
    "## 5. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# ü§ñ SECTION 5: Model Training Functions\n",
    "# =========================================================\n",
    "\n",
    "def train_lgb(X, y, groups, X_test, params, cat_feats, n_splits=5):\n",
    "    \"\"\"Train LightGBM with GroupKFold cross-validation.\"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    num_class = params.get('num_class', 1)\n",
    "    is_multiclass = params['objective'] == 'multiclass'\n",
    "    \n",
    "    oof_preds = np.zeros((len(X), num_class)) if is_multiclass else np.zeros(len(X))\n",
    "    test_preds_list = []\n",
    "    \n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_tr, y_tr = X.iloc[train_idx], y[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y[val_idx]\n",
    "        \n",
    "        # Handle unseen labels in multiclass\n",
    "        if is_multiclass:\n",
    "            missing = set(np.unique(y_val)) - set(np.unique(y_tr))\n",
    "            if missing:\n",
    "                add_idx = [val_idx[np.where(y_val == label)[0][0]] for label in missing]\n",
    "                X_tr = pd.concat([X_tr, X.iloc[add_idx]])\n",
    "                y_tr = np.concatenate([y_tr, y[add_idx]])\n",
    "        \n",
    "        dtrain = lgb.Dataset(X_tr, label=y_tr, categorical_feature=cat_feats)\n",
    "        dval = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_feats, reference=dtrain)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params, dtrain, valid_sets=[dval],\n",
    "            callbacks=[lgb.early_stopping(50, verbose=False), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict(X.iloc[val_idx])\n",
    "        test_preds_list.append(model.predict(X_test))\n",
    "    \n",
    "    return oof_preds, np.mean(test_preds_list, axis=0)\n",
    "\n",
    "\n",
    "def train_cat(X, y, groups, X_test, params, cat_indices, n_splits=5):\n",
    "    \"\"\"Train CatBoost with GroupKFold cross-validation.\"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    is_multiclass = 'MultiClass' in params.get('loss_function', '')\n",
    "    num_class = int(np.max(y) + 1) if is_multiclass else 1\n",
    "    \n",
    "    oof_preds = np.zeros((len(X), num_class)) if is_multiclass else np.zeros(len(X))\n",
    "    test_preds_list = []\n",
    "    \n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_tr, y_tr = X.iloc[train_idx], y[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y[val_idx]\n",
    "        \n",
    "        # Handle unseen labels in multiclass\n",
    "        if is_multiclass:\n",
    "            missing = set(np.unique(y_val)) - set(np.unique(y_tr))\n",
    "            if missing:\n",
    "                add_idx = [val_idx[np.where(y_val == label)[0][0]] for label in missing]\n",
    "                X_tr = pd.concat([X_tr, X.iloc[add_idx]])\n",
    "                y_tr = np.concatenate([y_tr, y[add_idx]])\n",
    "        \n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_indices)\n",
    "        val_pool = Pool(X_val, y_val, cat_features=cat_indices)\n",
    "        \n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=0)\n",
    "        \n",
    "        if is_multiclass:\n",
    "            oof_preds[val_idx] = model.predict_proba(val_pool)\n",
    "            test_preds_list.append(model.predict_proba(X_test))\n",
    "        else:\n",
    "            oof_preds[val_idx] = model.predict_proba(val_pool)[:, 1]\n",
    "            test_preds_list.append(model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    return oof_preds, np.mean(test_preds_list, axis=0)\n",
    "\n",
    "print(\"‚úì Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170da45",
   "metadata": {},
   "source": [
    "## 6. Train Models (50-50 LGBM + CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17be79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# üöÄ SECTION 6: Dual-Engine Training (50-50 Blending)\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[5/8] Starting Dual-Engine Training...\")\n",
    "print(\"  üåü Using 50-50 blending for better generalization\")\n",
    "\n",
    "# Model parameters\n",
    "lgb_common = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 3000,\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 31,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': RANDOM_SEED,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "cat_common = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 7,\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "if USE_GPU:\n",
    "    lgb_common['device'] = 'gpu'\n",
    "    cat_common.update({'task_type': 'GPU', 'devices': '0'})\n",
    "\n",
    "cat_indices = [X_next.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "# === Train Action ID Model ===\n",
    "print(\"\\n>> Training Action ID Predictor...\")\n",
    "lgb_p = {**lgb_common, 'objective': 'multiclass', \n",
    "         'num_class': len(le_action.classes_), 'metric': 'multi_logloss'}\n",
    "cat_p = {**cat_common, 'loss_function': 'MultiClass', 'eval_metric': 'MultiClass'}\n",
    "\n",
    "oof_lgb1, pred_lgb1 = train_lgb(X_next, y_action, groups_next, X_test, lgb_p, categorical_features)\n",
    "oof_cat1, pred_cat1 = train_cat(X_next, y_action, groups_next, X_test, cat_p, cat_indices)\n",
    "\n",
    "# 50-50 blending\n",
    "oof_blended_action = 0.5 * oof_lgb1 + 0.5 * oof_cat1\n",
    "final_proba_action = 0.5 * pred_lgb1 + 0.5 * pred_cat1\n",
    "\n",
    "action_f1 = f1_score(y_action, np.argmax(oof_blended_action, axis=1), average='macro')\n",
    "print(f\"   ‚úì Action Blended OOF F1: {action_f1:.4f}\")\n",
    "\n",
    "# === Train Point ID Model ===\n",
    "print(\"\\n>> Training Point ID Predictor...\")\n",
    "lgb_p['num_class'] = len(le_point.classes_)\n",
    "\n",
    "oof_lgb2, pred_lgb2 = train_lgb(X_next, y_point, groups_next, X_test, lgb_p, categorical_features)\n",
    "oof_cat2, pred_cat2 = train_cat(X_next, y_point, groups_next, X_test, cat_p, cat_indices)\n",
    "\n",
    "# 50-50 blending\n",
    "oof_blended_point = 0.5 * oof_lgb2 + 0.5 * oof_cat2\n",
    "final_proba_point = 0.5 * pred_lgb2 + 0.5 * pred_cat2\n",
    "\n",
    "point_f1 = f1_score(y_point, np.argmax(oof_blended_point, axis=1), average='macro')\n",
    "print(f\"   ‚úì Point Blended OOF F1: {point_f1:.4f}\")\n",
    "\n",
    "# === Train Outcome Model ===\n",
    "print(\"\\n>> Training Rally Outcome Predictor...\")\n",
    "lgb_p_bin = {**lgb_common, 'objective': 'binary', 'metric': 'auc'}\n",
    "cat_p_bin = {**cat_common, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}\n",
    "\n",
    "oof_lgb3, pred_lgb3 = train_lgb(X_outcome, y_outcome, groups_outcome, X_test, lgb_p_bin, categorical_features)\n",
    "oof_cat3, pred_cat3 = train_cat(X_outcome, y_outcome, groups_outcome, X_test, cat_p_bin, cat_indices)\n",
    "\n",
    "# 50-50 blending\n",
    "oof_blended_outcome = 0.5 * oof_lgb3 + 0.5 * oof_cat3\n",
    "final_proba_outcome = 0.5 * pred_lgb3 + 0.5 * pred_cat3\n",
    "\n",
    "outcome_auc = roc_auc_score(y_outcome, oof_blended_outcome)\n",
    "print(f\"   ‚úì Outcome Blended OOF AUC: {outcome_auc:.4f}\")\n",
    "\n",
    "print(\"\\n‚úì Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de37b6",
   "metadata": {},
   "source": [
    "## 7. Synchronize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45396d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# üîÑ SECTION 7: Prediction Synchronization\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[6/8] Synchronizing Predictions...\")\n",
    "\n",
    "def synchronize_endings(prob_act, prob_pt, le_act, le_pt, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Synchronize action and point predictions for rally endings.\n",
    "    Ensures both predict -1 when rally should end.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        act_neg1_idx = list(le_act.classes_).index(-1)\n",
    "        pt_neg1_idx = list(le_pt.classes_).index(-1)\n",
    "        \n",
    "        # Average ending probabilities\n",
    "        p_end = (prob_act[:, act_neg1_idx] + prob_pt[:, pt_neg1_idx]) / 2\n",
    "        \n",
    "        # Boost ending probabilities when both agree\n",
    "        prob_act_mod, prob_pt_mod = prob_act.copy(), prob_pt.copy()\n",
    "        prob_act_mod[p_end >= threshold, act_neg1_idx] = 2.0\n",
    "        prob_pt_mod[p_end >= threshold, pt_neg1_idx] = 2.0\n",
    "        \n",
    "        # Suppress ending when both disagree\n",
    "        prob_act_mod[p_end < threshold, act_neg1_idx] = 0.0\n",
    "        prob_pt_mod[p_end < threshold, pt_neg1_idx] = 0.0\n",
    "        \n",
    "        synced_count = (p_end >= threshold).sum()\n",
    "        print(f\"  ‚úì Synchronized {synced_count} rows to END state\")\n",
    "        \n",
    "        return (le_act.inverse_transform(np.argmax(prob_act_mod, axis=1)),\n",
    "                le_pt.inverse_transform(np.argmax(prob_pt_mod, axis=1)))\n",
    "    except ValueError:\n",
    "        print(\"  ‚ö† Warning: -1 label not found, skipping synchronization\")\n",
    "        return (le_act.inverse_transform(np.argmax(prob_act, axis=1)),\n",
    "                le_pt.inverse_transform(np.argmax(prob_pt, axis=1)))\n",
    "\n",
    "final_action, final_point = synchronize_endings(\n",
    "    final_proba_action, final_proba_point, le_action, le_point\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8cbcfe",
   "metadata": {},
   "source": [
    "## 8. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b15f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# üì§ SECTION 8: Generate Submission\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n[7/8] Generating Submission...\")\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'rally_uid': test_rally_uids,\n",
    "    'serverGetPoint': final_proba_outcome,\n",
    "    'pointId': final_point,\n",
    "    'actionId': final_action\n",
    "})\n",
    "\n",
    "# Merge with submission template to ensure all rally_uids are included\n",
    "final_submission = pd.merge(submission_df[['rally_uid']], submission, on='rally_uid', how='left')\n",
    "\n",
    "# Fill missing values\n",
    "final_submission.fillna({'serverGetPoint': 0.5}, inplace=True)\n",
    "\n",
    "# Fill missing action/point with most common values from training data\n",
    "valid_action_mode = train_df['actionId'].mode()[0]\n",
    "valid_point_mode = train_df['pointId'].mode()[0]\n",
    "final_submission['actionId'] = final_submission['actionId'].fillna(valid_action_mode).astype(int)\n",
    "final_submission['pointId'] = final_submission['pointId'].fillna(valid_point_mode).astype(int)\n",
    "\n",
    "print(f\"‚úì Submission created: {final_submission.shape}\")\n",
    "print(f\"‚úì First 5 rows:\")\n",
    "print(final_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "output_file = '../submissions/submission_gold.csv'\n",
    "final_submission.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"  ‚úì Saved to '{output_file}'\")\n",
    "print(f\"\\n  Summary:\")\n",
    "print(f\"    Total predictions: {len(final_submission)}\")\n",
    "print(f\"    Action -1 (end): {(final_submission['actionId'] == -1).sum()}\")\n",
    "print(f\"    Point -1 (end): {(final_submission['pointId'] == -1).sum()}\")\n",
    "print(f\"    Mean serverGetPoint: {final_submission['serverGetPoint'].mean():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ DONE! Gold version submission generated.\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä OOF Performance Summary:\")\n",
    "print(f\"  Action F1:  {action_f1:.4f}\")\n",
    "print(f\"  Point F1:   {point_f1:.4f}\")\n",
    "print(f\"  Outcome AUC: {outcome_auc:.4f}\")\n",
    "print(f\"\\nüí° Expected: Better generalization than V6 version\")\n",
    "print(f\"   (Higher Private score, lower Public score)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
